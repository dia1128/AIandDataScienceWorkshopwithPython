{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CNN_Assignment.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3lUjPPPmX3jk"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CTC3xzHnZWP0"
      },
      "source": [
        "# Step 1: Import/Fetch the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chN9U56WZcG4"
      },
      "source": [
        "\n",
        "Source: https://archive.ics.uci.edu/ml/datasets/Forest+Fires"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMZ466eaX670"
      },
      "source": [
        "dataset_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/forest-fires/forestfires.csv'\n",
        "forest_df = pd.read_csv(dataset_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IAgc9ki8ZpLr"
      },
      "source": [
        "Let's see the features and their data types"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h5A_mhFX7Vw",
        "outputId": "3954b2ec-6d26-4b70-e320-e7ccca025daf"
      },
      "source": [
        "forest_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 517 entries, 0 to 516\n",
            "Data columns (total 13 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   X       517 non-null    int64  \n",
            " 1   Y       517 non-null    int64  \n",
            " 2   month   517 non-null    object \n",
            " 3   day     517 non-null    object \n",
            " 4   FFMC    517 non-null    float64\n",
            " 5   DMC     517 non-null    float64\n",
            " 6   DC      517 non-null    float64\n",
            " 7   ISI     517 non-null    float64\n",
            " 8   temp    517 non-null    float64\n",
            " 9   RH      517 non-null    int64  \n",
            " 10  wind    517 non-null    float64\n",
            " 11  rain    517 non-null    float64\n",
            " 12  area    517 non-null    float64\n",
            "dtypes: float64(8), int64(3), object(2)\n",
            "memory usage: 52.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "felyQAgbTA5e",
        "outputId": "179b20df-ea00-4a0f-912e-b49b6c3a7466"
      },
      "source": [
        "forest_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "      <td>517.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>4.669246</td>\n",
              "      <td>4.299807</td>\n",
              "      <td>90.644681</td>\n",
              "      <td>110.872340</td>\n",
              "      <td>547.940039</td>\n",
              "      <td>9.021663</td>\n",
              "      <td>18.889168</td>\n",
              "      <td>44.288201</td>\n",
              "      <td>4.017602</td>\n",
              "      <td>0.021663</td>\n",
              "      <td>12.847292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>2.313778</td>\n",
              "      <td>1.229900</td>\n",
              "      <td>5.520111</td>\n",
              "      <td>64.046482</td>\n",
              "      <td>248.066192</td>\n",
              "      <td>4.559477</td>\n",
              "      <td>5.806625</td>\n",
              "      <td>16.317469</td>\n",
              "      <td>1.791653</td>\n",
              "      <td>0.295959</td>\n",
              "      <td>63.655818</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>18.700000</td>\n",
              "      <td>1.100000</td>\n",
              "      <td>7.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>90.200000</td>\n",
              "      <td>68.600000</td>\n",
              "      <td>437.700000</td>\n",
              "      <td>6.500000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>33.000000</td>\n",
              "      <td>2.700000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>91.600000</td>\n",
              "      <td>108.300000</td>\n",
              "      <td>664.200000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>19.300000</td>\n",
              "      <td>42.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.520000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>92.900000</td>\n",
              "      <td>142.400000</td>\n",
              "      <td>713.900000</td>\n",
              "      <td>10.800000</td>\n",
              "      <td>22.800000</td>\n",
              "      <td>53.000000</td>\n",
              "      <td>4.900000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.570000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>9.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>96.200000</td>\n",
              "      <td>291.300000</td>\n",
              "      <td>860.600000</td>\n",
              "      <td>56.100000</td>\n",
              "      <td>33.300000</td>\n",
              "      <td>100.000000</td>\n",
              "      <td>9.400000</td>\n",
              "      <td>6.400000</td>\n",
              "      <td>1090.840000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                X           Y        FFMC  ...        wind        rain         area\n",
              "count  517.000000  517.000000  517.000000  ...  517.000000  517.000000   517.000000\n",
              "mean     4.669246    4.299807   90.644681  ...    4.017602    0.021663    12.847292\n",
              "std      2.313778    1.229900    5.520111  ...    1.791653    0.295959    63.655818\n",
              "min      1.000000    2.000000   18.700000  ...    0.400000    0.000000     0.000000\n",
              "25%      3.000000    4.000000   90.200000  ...    2.700000    0.000000     0.000000\n",
              "50%      4.000000    4.000000   91.600000  ...    4.000000    0.000000     0.520000\n",
              "75%      7.000000    5.000000   92.900000  ...    4.900000    0.000000     6.570000\n",
              "max      9.000000    9.000000   96.200000  ...    9.400000    6.400000  1090.840000\n",
              "\n",
              "[8 rows x 11 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijngD7FtZuNf"
      },
      "source": [
        "The dataset contains 517 examples and 13 columns, 12 features and 1 label (areas)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iODZOtePX9bn",
        "outputId": "2d827f38-431c-4d95-a306-92ed202fef35"
      },
      "source": [
        "print(forest_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(517, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZTXD06DZ2el"
      },
      "source": [
        "## Split the dataset\n",
        "We will not go deep into analysis, but let's try to learn about the data we have. Before that, we will first split the dataset into training and test set.\n",
        "\n",
        "We will use Scikit-Learn train_test_split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGcMtlSDYBtY"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, test_data = train_test_split(forest_df, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNUarEOQYDrf",
        "outputId": "fa7a2efb-9d5e-4788-a698-7dafa6660a5f"
      },
      "source": [
        "print('The shape of training data: {}\\nThe shape of testing data: {}'.format(train_data.shape, test_data.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of training data: (413, 13)\n",
            "The shape of testing data: (104, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4JiGHMGcYFrX",
        "outputId": "7bfb1123-3a2b-4ca5-80a5-3a8b07d5e3e1"
      },
      "source": [
        "train_data.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>Y</th>\n",
              "      <th>month</th>\n",
              "      <th>day</th>\n",
              "      <th>FFMC</th>\n",
              "      <th>DMC</th>\n",
              "      <th>DC</th>\n",
              "      <th>ISI</th>\n",
              "      <th>temp</th>\n",
              "      <th>RH</th>\n",
              "      <th>wind</th>\n",
              "      <th>rain</th>\n",
              "      <th>area</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>sep</td>\n",
              "      <td>sat</td>\n",
              "      <td>92.2</td>\n",
              "      <td>102.3</td>\n",
              "      <td>751.5</td>\n",
              "      <td>8.4</td>\n",
              "      <td>23.5</td>\n",
              "      <td>27</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>sep</td>\n",
              "      <td>mon</td>\n",
              "      <td>90.9</td>\n",
              "      <td>126.5</td>\n",
              "      <td>686.5</td>\n",
              "      <td>7.0</td>\n",
              "      <td>17.7</td>\n",
              "      <td>39</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>aug</td>\n",
              "      <td>tue</td>\n",
              "      <td>92.1</td>\n",
              "      <td>152.6</td>\n",
              "      <td>658.2</td>\n",
              "      <td>14.3</td>\n",
              "      <td>20.2</td>\n",
              "      <td>47</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.09</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>aug</td>\n",
              "      <td>tue</td>\n",
              "      <td>96.1</td>\n",
              "      <td>181.1</td>\n",
              "      <td>671.2</td>\n",
              "      <td>14.3</td>\n",
              "      <td>32.3</td>\n",
              "      <td>27</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>14.68</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>feb</td>\n",
              "      <td>sun</td>\n",
              "      <td>86.8</td>\n",
              "      <td>15.6</td>\n",
              "      <td>48.3</td>\n",
              "      <td>3.9</td>\n",
              "      <td>12.4</td>\n",
              "      <td>53</td>\n",
              "      <td>2.2</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.38</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     X  Y month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain   area\n",
              "329  4  3   sep  sat  92.2  102.3  751.5   8.4  23.5  27   4.0   0.0   3.33\n",
              "173  4  4   sep  mon  90.9  126.5  686.5   7.0  17.7  39   2.2   0.0   3.07\n",
              "272  2  5   aug  tue  92.1  152.6  658.2  14.3  20.2  47   4.0   0.0   3.09\n",
              "497  3  4   aug  tue  96.1  181.1  671.2  14.3  32.3  27   2.2   0.0  14.68\n",
              "182  5  4   feb  sun  86.8   15.6   48.3   3.9  12.4  53   2.2   0.0   6.38"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1LKRDDB4aKOk"
      },
      "source": [
        "It seems that we have two categorical features, month and day. We will remember to encode them. For now we can see the number of samples in each month and later in each day."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62pC4Rxxaq0u",
        "outputId": "cd59d755-dc03-4d7a-8cfd-46fecab2eaaf"
      },
      "source": [
        "area_mean = train_data.area.mean()\n",
        "area_std = train_data.area.std()\n",
        "print(area_mean, area_std)\n",
        "\n",
        "normalized_area_column = (train_data.area - area_mean) / area_std"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11.132130750605326 45.65854799128173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "1eAD2oxhYHk-",
        "outputId": "4477798a-7aa4-49c5-8bef-725f4f22a40b"
      },
      "source": [
        "train_data['month'].value_counts().plot(kind='bar', figsize=(10,5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f82340cc510>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuTseT_kaRU5"
      },
      "source": [
        "# Preparing the Data for the Model\n",
        "Here we will do two things, \n",
        "\n",
        "1. one is to normalize numerical features -> area, ...\n",
        "2. and the second is to encode categorical features. -> month and day \n",
        "\n",
        "\n",
        "We can set up a pipeline to handle that.\n",
        "\n",
        "For simplicity, we will use Scikit-Learn processing functions.\n",
        "\n",
        "We will first separate features and label. We can use a function that can also be applied to test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7Ymb5WVYJq_"
      },
      "source": [
        "def get_feats_and_labels(data, label):\n",
        "  \"\"\" Take data and label as inputs, return features and labels separated \"\"\"\n",
        "\n",
        "  # drop the label column and save it in data_feats variable -> essentially getting everything other than the label column.\n",
        "  data_feats = data.drop(label, axis=1)\n",
        "\n",
        "  # labels of the dataset = label column in the dataframe.\n",
        "  data_label = data[label]\n",
        "\n",
        "  return data_feats, data_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3KMYxJ7abUz"
      },
      "source": [
        "Let's use the function created above to get the features and labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ah84b6hAYQWW"
      },
      "source": [
        "train_feats, train_label = get_feats_and_labels(train_data, 'area')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdMWsy_cXWkm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwjFKPTrYTGo"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "\n",
        "scaler = StandardScaler() # normalization engine\n",
        "encoder = OrdinalEncoder() # encoder engine\n",
        "\n",
        "# The column transformer requires lists of features\n",
        "\n",
        "num_feats = ['X', 'Y', 'FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain']\n",
        "cat_feats = ['month', 'day']\n",
        "\n",
        "# define the pipeline to scale the numeric features and handle categorical features\n",
        "final_pipe = ColumnTransformer([           \n",
        "   ('num', scaler, num_feats),  # normalize all numerical feats\n",
        "   ('cat', encoder, cat_feats),  # encode all categorical feats                      \n",
        "   # ('xyz', random, some_feats)\n",
        "])\n",
        "\n",
        "training_data_prepared = final_pipe.fit_transform(\n",
        "                                                    train_feats\n",
        "                                                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bsNP3V7Z_pj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXGaUZ7iae0t"
      },
      "source": [
        "\n",
        "Now, we can see the shape of the transformed dataset. It is a NumPy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKBRExfSYWKP",
        "outputId": "4105ed96-10f9-4aed-f5d6-aaa73339a1df"
      },
      "source": [
        "training_data_prepared.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(413, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFrMGwStYYOo",
        "outputId": "fb140a5a-de74-41b7-d9c6-ca752a298e4e"
      },
      "source": [
        "type(training_data_prepared)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7mKqKVCWZLN8",
        "outputId": "e73c3fb9-2c3f-4ba4-d7f7-306d9c94ffaf"
      },
      "source": [
        "training_data_prepared.min()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-12.080907025534259"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cboT1WekZQub",
        "outputId": "867c55d7-0359-43a1-87e6-1f2ca6cf31e4"
      },
      "source": [
        "training_data_prepared.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19.84930903705603"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Js37vfqZVpm",
        "outputId": "e38450a1-9f4e-4c50-b83b-d94126e6fdae"
      },
      "source": [
        "training_data_prepared[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.288472  , -0.26669645,  0.06165224,  0.21786634,  0.54913614,\n",
              "       -0.45543431, -0.2052724 , -0.33521489, -1.00892252, -0.06781709,\n",
              "       11.        ,  1.        ])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpEq24gKa80l"
      },
      "source": [
        "Also let's tranform the test set. Note that for the test set, we don't fit_transform().\n",
        "\n",
        "We will get the features and labels separated first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMssYn5FYa3P"
      },
      "source": [
        "test_feats, test_label = get_feats_and_labels(test_data, 'area')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugV4L_sSYyXg"
      },
      "source": [
        "test_data_prepared = final_pipe.transform(test_feats)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_Uvop9pYc04"
      },
      "source": [
        "train_label = train_label.to_numpy()\n",
        "test_label = test_label.to_numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wo5TOntpZXiW",
        "outputId": "7d968f4d-4745-4b7d-eb88-663ec7cea7d6"
      },
      "source": [
        "train_label[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.07"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbfzsO2ZbfV0"
      },
      "source": [
        "# Creating, Compiling and Training a Model\n",
        "Now that our data is prepared, it's time to create a neural network.\n",
        "Everytime we are creating a model in TensorFlow, we have to specify the input shape. In this example, the input shape will be:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHWUFXyEYe0o",
        "outputId": "9a65c5d4-5043-44ba-dd36-2075b65f8ce6"
      },
      "source": [
        "input_shape = training_data_prepared.shape[1:]\n",
        "input_shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "exknyvWlcrtT"
      },
      "source": [
        "# Step 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLf0LUOJdk1N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d74e21a-d4e9-4781-d215-f3f8bd611031"
      },
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(128, activation='relu', input_shape=(12,)),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation='relu') #relu activation always pass positive real numbers and returns zero for negative numbers.\n",
        "])\n",
        "\n",
        "# Now we compile the model\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               1664      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               16512     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 18,305\n",
            "Trainable params: 18,305\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_2TdC03d9XE"
      },
      "source": [
        "#Show your model summary here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJlBv5HBeSUO"
      },
      "source": [
        "# Step 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_IMeJtKYltQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd1be095-e807-45f1-effb-2504d5fe811e"
      },
      "source": [
        "#train your model here\n",
        "model.fit(x=training_data_prepared,\n",
        "          y=train_label,\n",
        "          epochs=500\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2155.6150\n",
            "Epoch 2/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2112.8560\n",
            "Epoch 3/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2103.9863\n",
            "Epoch 4/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2087.6606\n",
            "Epoch 5/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2075.4851\n",
            "Epoch 6/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2065.8865\n",
            "Epoch 7/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 2050.3379\n",
            "Epoch 8/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2039.2924\n",
            "Epoch 9/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2025.4836\n",
            "Epoch 10/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2017.4481\n",
            "Epoch 11/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 2006.6451\n",
            "Epoch 12/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1995.3398\n",
            "Epoch 13/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1990.7228\n",
            "Epoch 14/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1976.8759\n",
            "Epoch 15/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1966.2274\n",
            "Epoch 16/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1954.0616\n",
            "Epoch 17/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1949.0640\n",
            "Epoch 18/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1938.6364\n",
            "Epoch 19/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1923.5613\n",
            "Epoch 20/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1907.6881\n",
            "Epoch 21/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1898.8826\n",
            "Epoch 22/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1879.1824\n",
            "Epoch 23/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1869.9021\n",
            "Epoch 24/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1853.7076\n",
            "Epoch 25/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1843.8031\n",
            "Epoch 26/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1833.7784\n",
            "Epoch 27/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1829.1703\n",
            "Epoch 28/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1810.7778\n",
            "Epoch 29/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1787.4038\n",
            "Epoch 30/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1789.3618\n",
            "Epoch 31/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1759.4241\n",
            "Epoch 32/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1749.9780\n",
            "Epoch 33/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1733.5472\n",
            "Epoch 34/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1712.7411\n",
            "Epoch 35/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1706.4756\n",
            "Epoch 36/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1705.3693\n",
            "Epoch 37/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1671.9939\n",
            "Epoch 38/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1685.9746\n",
            "Epoch 39/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1648.6215\n",
            "Epoch 40/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1654.7220\n",
            "Epoch 41/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1612.1270\n",
            "Epoch 42/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1620.2041\n",
            "Epoch 43/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1639.1807\n",
            "Epoch 44/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1616.1211\n",
            "Epoch 45/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1577.3309\n",
            "Epoch 46/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1575.9512\n",
            "Epoch 47/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1567.7338\n",
            "Epoch 48/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1533.5869\n",
            "Epoch 49/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1527.8383\n",
            "Epoch 50/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1486.1884\n",
            "Epoch 51/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1487.2098\n",
            "Epoch 52/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1461.3859\n",
            "Epoch 53/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1440.8871\n",
            "Epoch 54/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1434.6442\n",
            "Epoch 55/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1406.4015\n",
            "Epoch 56/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1432.6888\n",
            "Epoch 57/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1393.9076\n",
            "Epoch 58/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1386.1774\n",
            "Epoch 59/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1353.0020\n",
            "Epoch 60/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1333.4484\n",
            "Epoch 61/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1332.4071\n",
            "Epoch 62/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1353.0219\n",
            "Epoch 63/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1320.3435\n",
            "Epoch 64/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1277.9872\n",
            "Epoch 65/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1282.8435\n",
            "Epoch 66/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1257.3629\n",
            "Epoch 67/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1235.2743\n",
            "Epoch 68/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1231.9083\n",
            "Epoch 69/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1196.8016\n",
            "Epoch 70/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1186.2765\n",
            "Epoch 71/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1174.2069\n",
            "Epoch 72/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1171.4021\n",
            "Epoch 73/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1136.6415\n",
            "Epoch 74/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1131.0389\n",
            "Epoch 75/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1109.6056\n",
            "Epoch 76/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1109.3341\n",
            "Epoch 77/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1086.1403\n",
            "Epoch 78/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1093.0116\n",
            "Epoch 79/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1103.6566\n",
            "Epoch 80/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1063.6202\n",
            "Epoch 81/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1076.2286\n",
            "Epoch 82/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 1035.0222\n",
            "Epoch 83/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 1019.0540\n",
            "Epoch 84/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 986.8162\n",
            "Epoch 85/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 981.3138\n",
            "Epoch 86/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 954.1541\n",
            "Epoch 87/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 948.3162\n",
            "Epoch 88/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 918.6701\n",
            "Epoch 89/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 963.1620\n",
            "Epoch 90/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 903.5558\n",
            "Epoch 91/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 904.6407\n",
            "Epoch 92/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 927.0984\n",
            "Epoch 93/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 873.5583\n",
            "Epoch 94/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 870.9445\n",
            "Epoch 95/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 834.2214\n",
            "Epoch 96/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 865.2932\n",
            "Epoch 97/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 851.2333\n",
            "Epoch 98/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 801.5743\n",
            "Epoch 99/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 789.7618\n",
            "Epoch 100/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 783.7006\n",
            "Epoch 101/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 812.9321\n",
            "Epoch 102/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 751.2676\n",
            "Epoch 103/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 751.7839\n",
            "Epoch 104/500\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 740.3608\n",
            "Epoch 105/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 753.2274\n",
            "Epoch 106/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 732.3875\n",
            "Epoch 107/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 701.0984\n",
            "Epoch 108/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 734.9243\n",
            "Epoch 109/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 713.9412\n",
            "Epoch 110/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 691.5455\n",
            "Epoch 111/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 678.3652\n",
            "Epoch 112/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 652.8947\n",
            "Epoch 113/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 639.2587\n",
            "Epoch 114/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 688.0772\n",
            "Epoch 115/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 642.4975\n",
            "Epoch 116/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 618.6733\n",
            "Epoch 117/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 619.0963\n",
            "Epoch 118/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 637.8376\n",
            "Epoch 119/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 620.4747\n",
            "Epoch 120/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 614.7087\n",
            "Epoch 121/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 580.6511\n",
            "Epoch 122/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 562.5190\n",
            "Epoch 123/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 632.2442\n",
            "Epoch 124/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 630.1204\n",
            "Epoch 125/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 512.9418\n",
            "Epoch 126/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 522.4211\n",
            "Epoch 127/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 492.2246\n",
            "Epoch 128/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 487.7336\n",
            "Epoch 129/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 514.8946\n",
            "Epoch 130/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 479.7048\n",
            "Epoch 131/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 464.3011\n",
            "Epoch 132/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 471.4512\n",
            "Epoch 133/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 453.6257\n",
            "Epoch 134/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 434.3737\n",
            "Epoch 135/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 468.3230\n",
            "Epoch 136/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 451.5821\n",
            "Epoch 137/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 421.2713\n",
            "Epoch 138/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 408.6515\n",
            "Epoch 139/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 387.8165\n",
            "Epoch 140/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 389.4153\n",
            "Epoch 141/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 386.9702\n",
            "Epoch 142/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 377.2920\n",
            "Epoch 143/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 380.1287\n",
            "Epoch 144/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 351.6700\n",
            "Epoch 145/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 355.2570\n",
            "Epoch 146/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 371.3260\n",
            "Epoch 147/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 333.1933\n",
            "Epoch 148/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 345.2271\n",
            "Epoch 149/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 376.9214\n",
            "Epoch 150/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 332.4048\n",
            "Epoch 151/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 330.8545\n",
            "Epoch 152/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 337.2934\n",
            "Epoch 153/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 382.1197\n",
            "Epoch 154/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 390.3382\n",
            "Epoch 155/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 289.9073\n",
            "Epoch 156/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 321.9349\n",
            "Epoch 157/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 267.3655\n",
            "Epoch 158/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 296.2397\n",
            "Epoch 159/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 265.2614\n",
            "Epoch 160/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 254.4426\n",
            "Epoch 161/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 261.3973\n",
            "Epoch 162/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 285.4038\n",
            "Epoch 163/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 250.8853\n",
            "Epoch 164/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 238.3422\n",
            "Epoch 165/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 259.1418\n",
            "Epoch 166/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 251.2433\n",
            "Epoch 167/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 252.3530\n",
            "Epoch 168/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 243.4568\n",
            "Epoch 169/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 217.7192\n",
            "Epoch 170/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 231.3612\n",
            "Epoch 171/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 209.4632\n",
            "Epoch 172/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 210.7079\n",
            "Epoch 173/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 204.5413\n",
            "Epoch 174/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 199.0845\n",
            "Epoch 175/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 199.4385\n",
            "Epoch 176/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 196.2095\n",
            "Epoch 177/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 188.1368\n",
            "Epoch 178/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 181.3172\n",
            "Epoch 179/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 198.4695\n",
            "Epoch 180/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 176.6978\n",
            "Epoch 181/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 182.8805\n",
            "Epoch 182/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 178.9534\n",
            "Epoch 183/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 192.3847\n",
            "Epoch 184/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 188.9765\n",
            "Epoch 185/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 172.4518\n",
            "Epoch 186/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 169.1415\n",
            "Epoch 187/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 163.7932\n",
            "Epoch 188/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 155.7066\n",
            "Epoch 189/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 159.1381\n",
            "Epoch 190/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 157.0180\n",
            "Epoch 191/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 154.4738\n",
            "Epoch 192/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 158.9245\n",
            "Epoch 193/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 152.1674\n",
            "Epoch 194/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 163.1264\n",
            "Epoch 195/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 150.2011\n",
            "Epoch 196/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 150.7050\n",
            "Epoch 197/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 159.7838\n",
            "Epoch 198/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 158.8839\n",
            "Epoch 199/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 163.4805\n",
            "Epoch 200/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 160.4054\n",
            "Epoch 201/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 137.5924\n",
            "Epoch 202/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 143.9290\n",
            "Epoch 203/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 140.4108\n",
            "Epoch 204/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 137.0758\n",
            "Epoch 205/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 134.6234\n",
            "Epoch 206/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 143.7994\n",
            "Epoch 207/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 137.1333\n",
            "Epoch 208/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 134.4018\n",
            "Epoch 209/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 126.1601\n",
            "Epoch 210/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 128.5492\n",
            "Epoch 211/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 122.0145\n",
            "Epoch 212/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 122.8507\n",
            "Epoch 213/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 121.3793\n",
            "Epoch 214/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 121.7021\n",
            "Epoch 215/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 121.3875\n",
            "Epoch 216/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 123.5618\n",
            "Epoch 217/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 126.2439\n",
            "Epoch 218/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 126.2989\n",
            "Epoch 219/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 133.8009\n",
            "Epoch 220/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 129.4052\n",
            "Epoch 221/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 128.6849\n",
            "Epoch 222/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 125.3544\n",
            "Epoch 223/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 125.2069\n",
            "Epoch 224/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 122.2310\n",
            "Epoch 225/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 124.0985\n",
            "Epoch 226/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 130.0777\n",
            "Epoch 227/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 131.1769\n",
            "Epoch 228/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 123.4050\n",
            "Epoch 229/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 118.2094\n",
            "Epoch 230/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 120.2221\n",
            "Epoch 231/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.6800\n",
            "Epoch 232/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 126.3721\n",
            "Epoch 233/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 139.9906\n",
            "Epoch 234/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 134.1107\n",
            "Epoch 235/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 126.9400\n",
            "Epoch 236/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 127.3079\n",
            "Epoch 237/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.1914\n",
            "Epoch 238/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 121.9696\n",
            "Epoch 239/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 118.8576\n",
            "Epoch 240/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 122.8213\n",
            "Epoch 241/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.9966\n",
            "Epoch 242/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 115.4819\n",
            "Epoch 243/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 116.1679\n",
            "Epoch 244/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.8225\n",
            "Epoch 245/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.1185\n",
            "Epoch 246/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 111.8793\n",
            "Epoch 247/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 120.7207\n",
            "Epoch 248/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.6542\n",
            "Epoch 249/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 115.9639\n",
            "Epoch 250/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.2665\n",
            "Epoch 251/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.5803\n",
            "Epoch 252/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.6439\n",
            "Epoch 253/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 111.9021\n",
            "Epoch 254/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.2671\n",
            "Epoch 255/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 125.1093\n",
            "Epoch 256/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 138.6671\n",
            "Epoch 257/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 132.5248\n",
            "Epoch 258/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.8662\n",
            "Epoch 259/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.4673\n",
            "Epoch 260/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 111.9920\n",
            "Epoch 261/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.4117\n",
            "Epoch 262/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.0472\n",
            "Epoch 263/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 114.9583\n",
            "Epoch 264/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 112.4145\n",
            "Epoch 265/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.0686\n",
            "Epoch 266/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 116.8097\n",
            "Epoch 267/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 112.7195\n",
            "Epoch 268/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.6203\n",
            "Epoch 269/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 109.6967\n",
            "Epoch 270/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.6146\n",
            "Epoch 271/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 109.6186\n",
            "Epoch 272/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.9450\n",
            "Epoch 273/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.7682\n",
            "Epoch 274/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.8729\n",
            "Epoch 275/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.0621\n",
            "Epoch 276/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.4488\n",
            "Epoch 277/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.9459\n",
            "Epoch 278/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 118.4489\n",
            "Epoch 279/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 124.2973\n",
            "Epoch 280/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 114.9304\n",
            "Epoch 281/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.5665\n",
            "Epoch 282/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 110.4554\n",
            "Epoch 283/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 118.6879\n",
            "Epoch 284/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 125.8307\n",
            "Epoch 285/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 122.5470\n",
            "Epoch 286/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 118.7006\n",
            "Epoch 287/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 113.9738\n",
            "Epoch 288/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 115.6682\n",
            "Epoch 289/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.2273\n",
            "Epoch 290/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.2717\n",
            "Epoch 291/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.4859\n",
            "Epoch 292/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 108.8390\n",
            "Epoch 293/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.1270\n",
            "Epoch 294/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.4325\n",
            "Epoch 295/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 118.3163\n",
            "Epoch 296/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.6723\n",
            "Epoch 297/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 118.2220\n",
            "Epoch 298/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 114.8148\n",
            "Epoch 299/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.9893\n",
            "Epoch 300/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 116.4093\n",
            "Epoch 301/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.9170\n",
            "Epoch 302/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 128.5269\n",
            "Epoch 303/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 116.6306\n",
            "Epoch 304/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 115.8460\n",
            "Epoch 305/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 118.2462\n",
            "Epoch 306/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.6299\n",
            "Epoch 307/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.3363\n",
            "Epoch 308/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 135.0323\n",
            "Epoch 309/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 152.7008\n",
            "Epoch 310/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 130.8033\n",
            "Epoch 311/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.0334\n",
            "Epoch 312/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.6640\n",
            "Epoch 313/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 124.7721\n",
            "Epoch 314/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.5159\n",
            "Epoch 315/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.4623\n",
            "Epoch 316/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.7749\n",
            "Epoch 317/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 113.4943\n",
            "Epoch 318/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.0574\n",
            "Epoch 319/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.1961\n",
            "Epoch 320/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.9019\n",
            "Epoch 321/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 113.2220\n",
            "Epoch 322/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.4738\n",
            "Epoch 323/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.3064\n",
            "Epoch 324/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.1077\n",
            "Epoch 325/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 111.4738\n",
            "Epoch 326/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 112.5835\n",
            "Epoch 327/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.1511\n",
            "Epoch 328/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.8578\n",
            "Epoch 329/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 121.8202\n",
            "Epoch 330/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 116.3892\n",
            "Epoch 331/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 122.6121\n",
            "Epoch 332/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.6880\n",
            "Epoch 333/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.1336\n",
            "Epoch 334/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.8452\n",
            "Epoch 335/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 135.8272\n",
            "Epoch 336/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.8699\n",
            "Epoch 337/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.2222\n",
            "Epoch 338/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 132.7141\n",
            "Epoch 339/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 130.6160\n",
            "Epoch 340/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 139.6061\n",
            "Epoch 341/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 116.5601\n",
            "Epoch 342/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.7146\n",
            "Epoch 343/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 114.4143\n",
            "Epoch 344/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.3078\n",
            "Epoch 345/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 120.3688\n",
            "Epoch 346/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.5834\n",
            "Epoch 347/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.5262\n",
            "Epoch 348/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 113.8290\n",
            "Epoch 349/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 116.8183\n",
            "Epoch 350/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 118.7784\n",
            "Epoch 351/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 119.9109\n",
            "Epoch 352/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 121.0250\n",
            "Epoch 353/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 124.9725\n",
            "Epoch 354/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 123.6263\n",
            "Epoch 355/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 125.5422\n",
            "Epoch 356/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 120.0341\n",
            "Epoch 357/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 119.5403\n",
            "Epoch 358/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 121.0756\n",
            "Epoch 359/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.0785\n",
            "Epoch 360/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 120.8454\n",
            "Epoch 361/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 120.5081\n",
            "Epoch 362/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 119.1060\n",
            "Epoch 363/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 111.2220\n",
            "Epoch 364/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.6107\n",
            "Epoch 365/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.6308\n",
            "Epoch 366/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.8366\n",
            "Epoch 367/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 114.4879\n",
            "Epoch 368/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 147.1391\n",
            "Epoch 369/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 126.8037\n",
            "Epoch 370/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 128.0271\n",
            "Epoch 371/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 127.8924\n",
            "Epoch 372/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 124.6095\n",
            "Epoch 373/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 120.6404\n",
            "Epoch 374/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.6867\n",
            "Epoch 375/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.1727\n",
            "Epoch 376/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.6197\n",
            "Epoch 377/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.2930\n",
            "Epoch 378/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.5639\n",
            "Epoch 379/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 124.5921\n",
            "Epoch 380/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 119.4438\n",
            "Epoch 381/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 132.6214\n",
            "Epoch 382/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 123.7685\n",
            "Epoch 383/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 127.3688\n",
            "Epoch 384/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 125.9727\n",
            "Epoch 385/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 118.9575\n",
            "Epoch 386/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 120.4169\n",
            "Epoch 387/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 114.7933\n",
            "Epoch 388/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.4866\n",
            "Epoch 389/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.9369\n",
            "Epoch 390/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.1610\n",
            "Epoch 391/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.8334\n",
            "Epoch 392/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 115.4995\n",
            "Epoch 393/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 118.0997\n",
            "Epoch 394/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 118.5008\n",
            "Epoch 395/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 120.6829\n",
            "Epoch 396/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 120.6563\n",
            "Epoch 397/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 121.5176\n",
            "Epoch 398/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 123.3067\n",
            "Epoch 399/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 122.1410\n",
            "Epoch 400/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 125.5637\n",
            "Epoch 401/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 120.2117\n",
            "Epoch 402/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 119.6320\n",
            "Epoch 403/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 125.9090\n",
            "Epoch 404/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 132.6656\n",
            "Epoch 405/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 124.1992\n",
            "Epoch 406/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 139.3449\n",
            "Epoch 407/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 133.4723\n",
            "Epoch 408/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 132.4675\n",
            "Epoch 409/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 145.4652\n",
            "Epoch 410/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 177.1779\n",
            "Epoch 411/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 208.0226\n",
            "Epoch 412/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 192.2600\n",
            "Epoch 413/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 177.1914\n",
            "Epoch 414/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 135.8582\n",
            "Epoch 415/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 128.0114\n",
            "Epoch 416/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 131.3180\n",
            "Epoch 417/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 125.9764\n",
            "Epoch 418/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 131.1886\n",
            "Epoch 419/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 122.1728\n",
            "Epoch 420/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 113.0228\n",
            "Epoch 421/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.3136\n",
            "Epoch 422/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.1006\n",
            "Epoch 423/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 130.3122\n",
            "Epoch 424/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 121.0253\n",
            "Epoch 425/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 126.3265\n",
            "Epoch 426/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 129.6119\n",
            "Epoch 427/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 127.9538\n",
            "Epoch 428/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.7489\n",
            "Epoch 429/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 125.1189\n",
            "Epoch 430/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 125.6765\n",
            "Epoch 431/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.4095\n",
            "Epoch 432/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.8077\n",
            "Epoch 433/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.1106\n",
            "Epoch 434/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 109.8264\n",
            "Epoch 435/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 114.8762\n",
            "Epoch 436/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 119.6930\n",
            "Epoch 437/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 115.0367\n",
            "Epoch 438/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 124.9983\n",
            "Epoch 439/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 124.6215\n",
            "Epoch 440/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 131.5947\n",
            "Epoch 441/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.9067\n",
            "Epoch 442/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 110.8888\n",
            "Epoch 443/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 110.3978\n",
            "Epoch 444/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 109.8996\n",
            "Epoch 445/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 110.1362\n",
            "Epoch 446/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 112.4109\n",
            "Epoch 447/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 120.2136\n",
            "Epoch 448/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 123.4510\n",
            "Epoch 449/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.5538\n",
            "Epoch 450/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 116.1873\n",
            "Epoch 451/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 112.2130\n",
            "Epoch 452/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 123.9796\n",
            "Epoch 453/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 136.1043\n",
            "Epoch 454/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 125.1063\n",
            "Epoch 455/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 125.2645\n",
            "Epoch 456/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 123.1138\n",
            "Epoch 457/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 118.0778\n",
            "Epoch 458/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 127.9787\n",
            "Epoch 459/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.4624\n",
            "Epoch 460/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 134.3869\n",
            "Epoch 461/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 139.9661\n",
            "Epoch 462/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 123.0809\n",
            "Epoch 463/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 125.6796\n",
            "Epoch 464/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 124.8525\n",
            "Epoch 465/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 122.3409\n",
            "Epoch 466/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.7945\n",
            "Epoch 467/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 111.9219\n",
            "Epoch 468/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 119.5760\n",
            "Epoch 469/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 111.6107\n",
            "Epoch 470/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 113.7594\n",
            "Epoch 471/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 115.9998\n",
            "Epoch 472/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 111.0604\n",
            "Epoch 473/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 109.2457\n",
            "Epoch 474/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.0528\n",
            "Epoch 475/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 108.6619\n",
            "Epoch 476/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 109.2609\n",
            "Epoch 477/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 115.5561\n",
            "Epoch 478/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 126.8525\n",
            "Epoch 479/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.4822\n",
            "Epoch 480/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.0821\n",
            "Epoch 481/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.1170\n",
            "Epoch 482/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 114.0712\n",
            "Epoch 483/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 111.8236\n",
            "Epoch 484/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 120.7814\n",
            "Epoch 485/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 123.6786\n",
            "Epoch 486/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.1182\n",
            "Epoch 487/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 120.4953\n",
            "Epoch 488/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 121.5039\n",
            "Epoch 489/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 117.8360\n",
            "Epoch 490/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 111.8018\n",
            "Epoch 491/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 113.2119\n",
            "Epoch 492/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 117.8952\n",
            "Epoch 493/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 118.2021\n",
            "Epoch 494/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 119.9452\n",
            "Epoch 495/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 113.9942\n",
            "Epoch 496/500\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 116.1354\n",
            "Epoch 497/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 111.4649\n",
            "Epoch 498/500\n",
            "13/13 [==============================] - 0s 2ms/step - loss: 120.9547\n",
            "Epoch 499/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 113.0236\n",
            "Epoch 500/500\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 115.8568\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f822e270b10>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFV2vS41b-yP"
      },
      "source": [
        "# Evaluating a Model\n",
        "After we have trained the model, the next step is to evaluate it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg80x4IvY3_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79bb1b07-0482-4b73-ac06-00a0df40a120"
      },
      "source": [
        "#To evaluate the model, run this cell\n",
        "model.evaluate(test_data_prepared, test_label) # OVERFITTING -> DROPOUT."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 0s 3ms/step - loss: 13371.1807\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13371.1806640625"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEuoD0eecHnm"
      },
      "source": [
        "#Bonus: Improving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AeAwfDX8ecWk"
      },
      "source": [
        "#Can you improve the model? "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}